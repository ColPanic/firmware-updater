{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iPJnDH0HhXB"
      },
      "source": [
        "<img src=\"https://imagedelivery.net/Dr98IMl5gQ9tPkFM5JRcng/3e5f6fbd-9bc6-4aa1-368e-e8bb1d6ca100/Ultra\" alt=\"Image description\" width=\"160\" />\n",
        "\n",
        "<br/>\n",
        "\n",
        "# Introduction to Contextual AI Platform using the Python Client\n",
        "\n",
        "Contextual AI lets you create and use generative AI agents. This notebook introduces an end-to-end example workflow for creating a Retrieval-Augmented Generation (RAG) agent for a financial use case. This notebook uses the Python client.\n",
        "\n",
        "This notebook covers the following steps:\n",
        "- Creating a Datastore\n",
        "- Ingesting Documents\n",
        "- Creating an RAG Agent\n",
        "- Querying an RAG Agent\n",
        "- Evaluating an RAG Agent\n",
        "- Improving the RAG Agent (Updating prompt)\n",
        "\n",
        "The notebook can be run in under 15 minutes. The full documentation is available at [docs.contextual.ai](https://docs.contextual.ai/)\n",
        "\n",
        "To run this notebook interactively, open it in Google Colab. However, make sure to copy over the additional files.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ContextualAI/examples/blob/main/01-getting-started/end-to-end-example.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SxgKmrVy9csa",
        "outputId": "a2182f16-aaa2-4a9e-84a6-07df65a402de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contextual-client in /usr/local/lib/python3.12/dist-packages (0.8.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: google in /usr/local/lib/python3.12/dist-packages (2.0.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from contextual-client) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from contextual-client) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from contextual-client) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from contextual-client) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from contextual-client) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from contextual-client) (4.15.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from google) (4.13.5)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->contextual-client) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->contextual-client) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->contextual-client) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->contextual-client) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->contextual-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->contextual-client) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->contextual-client) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->google) (2.8)\n"
          ]
        }
      ],
      "source": [
        "%pip install contextual-client matplotlib google"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Wwfm2FME9csb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import List, Optional, Dict\n",
        "from IPython.display import display, JSON\n",
        "import pandas as pd\n",
        "from contextual import ContextualAI\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsARIi5t9csb"
      },
      "source": [
        "Add your API Key here. If you are using our US Cloud, you can leave the default values.\n",
        "If you are on another instance, modify `base_url` to the appropriate address."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4wJG66VTIQvO"
      },
      "outputs": [],
      "source": [
        "#Setup API key\n",
        "#os.environ[\"CONTEXTUAL_API_KEY\"] = API_KEY  # You can store the API key is stored as the environment variable\n",
        "\n",
        "client = ContextualAI(\n",
        "    api_key=userdata.get(\"CONTEXTUAL_API_KEY\"),\n",
        "    base_url=\"http://api.contextual.ai/v1\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcqh_-j1MzCn"
      },
      "source": [
        "## Step 1: Create your Datastore\n",
        "\n",
        "\n",
        "You will need to first create a datastore for your agent using the  /datastores endpoint. A datastore is secure storage for data. Each agent will have its own datastore for storing data securely."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlulbIvjdbZA",
        "outputId": "793f1387-d484-4ff0-a736-66d8d4aa6c30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datastore ID: 322fb593-bad1-4a61-b5b5-d146e4ba673b\n"
          ]
        }
      ],
      "source": [
        "result = client.datastores.create(name=\"Demo_fin_rag\")\n",
        "datastore_id = result.id\n",
        "print(f\"Datastore ID: {datastore_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IkAep8Vf29_"
      },
      "source": [
        "## Step 2: Ingest Documents into your Datastore\n",
        "\n",
        "You can now ingest documents into your Agent's datastore using the /datastores endpoint. Documents must be a PDF or HTML file.\n",
        "\n",
        "\n",
        "I am using an example PDF. You can also use your own documents here. If you have very long documents (hundreds of pages), processing can take longer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edHs_fxj9csd"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tstsRjJv9cse"
      },
      "source": [
        "Let's ingest the file to start the parsing/extraction process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hqeBpmG-9cse",
        "outputId": "354b1f5e-05d9-48e5-a814-51795a941329",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully uploaded to datastore 322fb593-bad1-4a61-b5b5-d146e4ba673b\n"
          ]
        }
      ],
      "source": [
        "with open('Fiska_Tech_Doc.docx', 'rb') as f:\n",
        "    ingestion_result = client.datastores.documents.ingest(datastore_id, file=f)\n",
        "    document_id = ingestion_result.id\n",
        "    print(f\"Successfully uploaded to datastore {datastore_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mZdyD5cK8lc"
      },
      "source": [
        "Once ingested, you can view the list of documents, see their metadata, and also delete documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "j78jlN1_lIbM",
        "outputId": "797fce1e-75a0-4c2d-b016-62209eb69d91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document metadata: DocumentMetadata(id='19990e7f-2148-4cb5-ad84-46a4a9b9b172', created_at='2025-09-10T19:13:34.416122', name='Fiska_Tech_Doc.docx', status='processing', custom_metadata={}, custom_metadata_config={}, has_access=True, ingestion_config={'parsing': {'figure_captioning_prompt': None, 'figure_caption_mode': 'default', 'enable_split_tables': True, 'max_split_table_cells': 100, 'enable_table_revision': False, 'ocr_level': 'auto', 'use_hyperlink_extraction': False, 'enable_vlm_hierarchy_inference': True, 'layout_model': 'dit', 'extractor_type': 'layout_block', 'vlm_captioning_model': None, 'vlm_hierarchy_model': None, 'vlm_doc_name_model': None, 'vlm_markdown_reviser_model': None, 'vlm_table_reviser_model': None, 'enable_table_reviser_thinking': None}, 'chunking': {'chunking_mode': 'hierarchy_depth', 'max_chunk_length_tokens': 768, 'min_chunk_length_tokens': 384, 'enable_hierarchy_based_contextualization': True, 'enable_contextualization': None, 'enable_section_based_contextualization': None}, 'html_config': {'max_recursive_depth': 5, 'markdown_links_mode': 'EXTERNAL', 'precise_image_attribution': True, 'enable_section_extraction': True, 'enable_table_links_addition': True, 'max_chunk_length_tokens': 768, 'enable_v2_extraction_pipeline': True}, 'ingestion_types': None, 'extraction': None, 'enable_v2_extraction_pipeline': True}, updated_at=None)\n"
          ]
        }
      ],
      "source": [
        "metadata = client.datastores.documents.metadata(datastore_id = datastore_id, document_id = document_id)\n",
        "print(\"Document metadata:\", metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-yBQYpM9csf"
      },
      "source": [
        "You can also export the parsed document for use outside of Contextual.  \n",
        "\n",
        "**Note:** It may take a few minutes for the document to be ingested and processed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hCEijPv19csf"
      },
      "outputs": [],
      "source": [
        "getdocs = client.datastores.documents.get_parse_result(datastore_id=datastore_id, document_id=document_id,output_types=\"markdown-document\")\n",
        "getdocs.markdown_document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcTyR5QeHw7z"
      },
      "source": [
        "## Step 3: Create your Agent\n",
        "\n",
        "Next let's create an Agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymCcfHR1Lra6"
      },
      "outputs": [],
      "source": [
        "app_response = client.agents.create(\n",
        "    name=\"Demo BRD Agent\",\n",
        "    description=\"Agent for looking at client documentation & planning SaaS integrations\",\n",
        "    datastore_ids=[datastore_id]\n",
        ")\n",
        "agent_id= app_response.id\n",
        "print(f\"Agent ID created: {agent_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFq4oMe9gMuz"
      },
      "source": [
        "## Step 4: Query your Agent\n",
        "\n",
        "Let's query our agent to see if its working. The required information is the agent_id and messages.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wE4d616-rseT"
      },
      "outputs": [],
      "source": [
        "query_result = client.agents.query.create(\n",
        "    agent_id=agent_id,\n",
        "    messages=[{\n",
        "        \"content\": \"what was the sales for Apple in 2022\",\n",
        "        \"role\": \"user\"\n",
        "    }]\n",
        ")\n",
        "print(query_result.message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XG-L-gO9csf"
      },
      "source": [
        "There is much more information you can access from the query result. You can view the attributions in an image format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ozRLyVGS9xb"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import io\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def display_base64_image(base64_string):\n",
        "    # Decode base64 string\n",
        "    img_data = base64.b64decode(base64_string)\n",
        "\n",
        "    # Create PIL Image object\n",
        "    img = Image.open(io.BytesIO(img_data))\n",
        "\n",
        "    # Display using matplotlib\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    return img\n",
        "\n",
        "# Retrieve the first referenced document `retrieval_contents[0]\n",
        "ret_result = client.agents.query.retrieval_info(message_id = query_result.message_id, agent_id=agent_id,content_ids=[query_result.retrieval_contents[0].content_id])\n",
        "print(\"\\nRetrieval Info:\", ret_result)\n",
        "base64_string = ret_result.content_metadatas[0].page_img\n",
        "img = display_base64_image(base64_string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5annKXLeNCGT"
      },
      "source": [
        "## Step 5: Evaluate your Agent\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuUe0Hbm9csg"
      },
      "source": [
        "Evaluation endpoints allow you to evaluate your Agent. Contextual support using a variety of evalulation frameworks, such as RAGAS, and different evaluation platforms, such as Langfuse. You will find additional examples around evaluation in this repo.\n",
        "\n",
        "For those using unit tests, we also offer our `lmunit` endpoint, get more details [here](https://contextual.ai/blog/lmunit/)\n",
        "\n",
        "LMUnit is specifically trained for evaluating natural language unit tests and provides:\n",
        "* Scores on a continuous 1-5 scale\n",
        "* Consistent evaluation across different criteria\n",
        "* Better performance than general-purpose LLMs like GPT-4\n",
        "* Ability to add rubrics to evaluation\n",
        "* Apply thresholds to get binary scores, e.g., if score is greater than 2.5 is 1 else 0\n",
        "\n",
        "Let's start with a simple example to understand how LMUnit works:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBt0QPwg9csg"
      },
      "outputs": [],
      "source": [
        "response = client.lmunit.create(\n",
        "                    query=\"What was Apple's total net sales for 2022?\",\n",
        "                    response=\"For the quarter ended December 31, 2022, Apple reported total net sales of $117,154 million, representing a decrease from $123,945 million in the same quarter of the previous year (December 25, 2021).[1]() This quarterly data represents only one quarter of Apple's fiscal year. The full-year 2022 total net sales figure is not available in the provided documentation. The sales breakdown for Q4 2022 was: - Products: $96,388 million[1]() - Services: $20,766 million[1]() - Total: $117,154 million[1]() To provide the total net sales for the full fiscal year 2022, we would need additional quarterly data from the other three quarters of the year.\",\n",
        "                    unit_test=\"Does the response avoid unnecessary information?\"\n",
        "                )\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "692gSc7ZNyve"
      },
      "source": [
        "## Step 6: Improving your Agent\n",
        "\n",
        "Contexual AI provides many settings for improving overall performance including on the retrieval side or the generation side. A simple example is modifying the system prompt, you can modify the agent as follows.\n",
        "For additional ways to improve the agent, look over the [Improve Agent Performance](https://github.com/ContextualAI/examples/tree/main/06-improve-agent-performance) notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UEnh8MM9csg"
      },
      "source": [
        "### 6.1 Revising the system prompt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcjEMEgi9csg"
      },
      "source": [
        "After initial testing, you may want to revise the system prompt. Here I have an updated prompt with additional information in the critical guidelines section.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jAvU8qg9csg"
      },
      "outputs": [],
      "source": [
        "system_prompt = '''\n",
        "You are a financial AI assistant created by Contextual AI to help analysts with 10-K forms and related financial documentation. Provide precise, accurate information sourced exclusively from the provided documents.\n",
        "\n",
        "## Guidelines\n",
        "Source-Only: Use only information from provided documentation. No opinions, speculation, or external knowledge.\n",
        "Financial Precision: Use exact terminology, figures, and descriptions as they appear in the documents.\n",
        "Concise & Relevant: Keep responses focused on financial analysis needs. Prioritize quantitative data and material business information.\n",
        "Exact Terms: Use financial acronyms and abbreviations exactly as they appear (GAAP, EBITDA, SG&A, etc.).\n",
        "Markdown: Apply formatting for financial tables, lists, and data presentations.\n",
        "\n",
        "## Response Protocol\n",
        "Direct Answer: Answer the question with relevant financial data, then STOP. Avoid unnecessary explanations.\n",
        "Missing Data: If information isn't available, respond: \"I don't have relevant documentation containing that financial information.\"\n",
        "Identity/Non-Financial Queries: Respond: \"I am a financial AI assistant created by Contextual AI specializing in 10-K analysis. I don't have relevant documentation about that topic, but feel free to ask about financial information from the provided documents!\"\n",
        "\n",
        "Your role is to extract and present financial information accurately to support analyst decision-making, not to provide investment advice.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1b3owHY9csg"
      },
      "source": [
        "Let's now update the agent. And verify that changes by checking the agent metadata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtSpA7kU9csg"
      },
      "outputs": [],
      "source": [
        "client.agents.update(agent_id=agent_id, system_prompt=system_prompt)\n",
        "\n",
        "agent_config = client.agents.metadata(agent_id=agent_id)\n",
        "print (agent_config.system_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKAmujbKgUBj"
      },
      "source": [
        "## Next Steps\n",
        "\n",
        "In this Notebook, we've created a RAG agent in the finance domain, evaluating the agent, and improved it for better performance. To find further methods for improving your RAG Agent, check out the [Improvement notebook](https://colab.research.google.com/github/ContextualAI/examples/blob/main/06-improve-agent-performance/improvement-overview.ipynb) in this repo.  \n",
        "\n",
        "You can learn more at [docs.contextual.ai](https://docs.contextual.ai/).   \n",
        "\n",
        "Finally, reach out to your account team if you have further questions or issues."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}